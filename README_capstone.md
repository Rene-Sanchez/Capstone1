The dataset used here was obtained from Kaggle and contains 2017 songs with their attribute scores and whether or not they were liked by the user. Fortunately, this data was gathered from the Spotify API, therefore the data started off very clean with the columns properly formatted as int and float types. Regardless of this, I checked for missing values anyway to make sure and indeed there were none.

The Spotify API is freely available to generate the attribute scores of a single song or set of songs for analysis and prediction purposes. However, in order to get specific user data with which to train a recommendation engine the user must provide permission via their Spotify app in order for their playlists and liked songs to be accessible. This presents some limitations as to what a third party developer can do as the following recommendation engine may or may not generalize to sets of users.

In inspecting the distribution graphs of the attribute scores, we see that some are normally distributed and others are heavily skewed. In context, what this means is that the attributes that are normally distributed are not concentrated at certain values but are instead are relatively evenly spread out over the range. By contrast, the skewed attributes provide evidence for preferred values for the given attributes by means of the concentration of songs around that value. With these variables of interest in hand I proceeded to conduct a statistical examination of the dataset to identify variables of interest numerically. 

To do this, I split the dataset into the songs that were liked and those not liked and examined the correlations within the sets and mean differences between the sets. Interestingly, the set of liked songs exhibited only one correlation > |4| between loudness and energy (.646), which suggests that the scores of the likes songs are widely and even distributed with significant variety. By Contrast, the disliked set produced a number or correlations between energy, acousticness, loudness, dancability, and valence suggesting there is some pattern present in the disliked set. 

Next, using the variables that had considerable mean differences between sets, Z-tests were conducted to determine if these differences were significant. Indeed acousticness, instramentalness, loudness, duration, and speechiness all had significantly different means suggesting they are prominent features that the user uses to determine whether or not they like it.
